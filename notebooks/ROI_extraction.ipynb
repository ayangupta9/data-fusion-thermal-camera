{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for ROI Extraction\n",
    "We will start with adjusting the color space\n",
    "From some EDA, I have found LAB, LUV and YUV colors spaces to be useful for ROI extraction task\n",
    "\n",
    "Here's the current pipeline\n",
    "- Convert RGB image into another color space (possibly LAB)\n",
    "- Extract L channel and apply enhancement using `convertScaleAbs` function from cv2 [alpha = 2.0, beta=-50]\n",
    "- Dilate image to increase ROI area\n",
    "- Apply binary threshold on the image with threshold value of 200\n",
    "- Applying `findContours` on the thresholded image\n",
    "- Fetch each contours area and sort in descending order.\n",
    "- Pick highest contour area objects and create bounding boxes using `boundingRect`\n",
    "- These will be used as ROIs for extraction of hot liquid\n",
    "\n",
    "- Need to apply some kind of technique to identify how many objects are there in the frame. \n",
    "    - Also, how do we know the ROI is actually a coffee mug or glass or something else.\n",
    "        Template Matching, or maybe some other technique. \n",
    "            Some kind of edge detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio as io\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from matplotlib import patches\n",
    "from pycocotools import mask as M\n",
    "from pprint import pprint\n",
    "sys.path.append('../scripts')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.yaml','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "img_paths = sorted(glob.glob(config['new_dataset']['images']+'/img_thermal_*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_convs = {\n",
    "    'HLS':cv2.COLOR_RGB2HLS,\n",
    "    'HSV': cv2.COLOR_RGB2HSV,\n",
    "    'LAB':cv2.COLOR_RGB2LAB,\n",
    "    'LUV': cv2.COLOR_RGB2LUV,\n",
    "    'YUV': cv2.COLOR_RGB2YUV\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_image(image_path, apply_ce=False, apply_blur=False, apply_clahe=False, apply_dilation=False):\n",
    "    c_img = utils.rotate_to_vertical(image_path)\n",
    "    og_img = c_img\n",
    "    c_img = cv2.cvtColor(c_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if apply_clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(32,32))\n",
    "        c_img = clahe.apply(c_img)\n",
    "    \n",
    "    if apply_ce:\n",
    "        c_img = cv2.equalizeHist(c_img)\n",
    "    \n",
    "    if apply_blur:\n",
    "        c_img = cv2.GaussianBlur(c_img, (51, 51), 15)\n",
    "\n",
    "    cvt_img = cv2.cvtColor(og_img, cv2.COLOR_RGB2LAB)\n",
    "    # cvt_img = og_img\n",
    "    # img_dilate = None\n",
    "    \n",
    "    enhanced_img = cv2.convertScaleAbs(cvt_img[...,0], alpha=2,beta=-70)\n",
    "    if apply_dilation:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # Adjust kernel size as needed\n",
    "        img_dilate = cv2.dilate(enhanced_img, kernel, iterations=2)\n",
    "    \n",
    "    return c_img, og_img, cvt_img, enhanced_img, img_dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_img(img, t_value=200, apply_open=False, apply_erode_n_dilate=False):\n",
    "    _, img = cv2.threshold(img, t_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    if apply_open:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31, 31))  # Adjust kernel size as needed\n",
    "        opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        img = opened\n",
    "        \n",
    "    if apply_erode_n_dilate:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6, 6))  # Adjust kernel size as needed\n",
    "        eroded = cv2.erode(img, kernel, iterations=6)\n",
    "        dilated = cv2.dilate(eroded, kernel, iterations=4)\n",
    "        img = dilated\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_n_bbox(img):\n",
    "    contours, _ = cv2.findContours(img.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_contours = [np.squeeze(c, axis=1) for c in contours]\n",
    "\n",
    "    contour_areas = pd.DataFrame([(int(i), cv2.contourArea(c)) for i, c in enumerate(contours)])\n",
    "    contour_areas.columns = ['index', 'area']\n",
    "    contour_areas.sort_values('area', ascending=False, inplace=True)\n",
    "    contour_areas['index'] = contour_areas['index'].astype(int)\n",
    "    \n",
    "    bboxes = [cv2.boundingRect(new_contours[int(row[0])]) for idx, row in enumerate(contour_areas.iloc[:4].values)]\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATTERN MATCHING MISSING!\n",
    "important for identifying if the identified ROI is of a glass/mug or something else hot\n",
    "    - might have to make use of other channels to see if liquid is in the mug and is possibly less than the height of the cup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = img_paths.__len__()  # total number of images\n",
    "grid_shape = (int(np.sqrt(n))+1, int(np.sqrt(n))+1)\n",
    "fig, axs = plt.subplots(nrows=grid_shape[0], ncols=grid_shape[1], figsize=(25, 25))\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, img_p in tqdm_notebook(enumerate(img_paths)):\n",
    "    c_img, og_img, cvt_img, enhanced_img, img_dilate = get_enhanced_image(image_path=img_p, apply_dilation=True, apply_blur=True, apply_ce=True)\n",
    "    t_img = get_threshold_img(img_dilate, apply_open=True, apply_erode_n_dilate=True)\n",
    "    bboxes = get_contours_n_bbox(t_img)\n",
    "    \n",
    "    ax = axs[i]\n",
    "\n",
    "    ax.imshow(img_dilate)\n",
    "    # ax.imshow(t_img, alpha=0.5)\n",
    "    for bbox in bboxes:\n",
    "        ax.add_patch(patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], facecolor='none', edgecolor='white'))\n",
    "    \n",
    "    ax.set_title(i)\n",
    "    ax.axis('off')\n",
    "\n",
    "for ax in axs[n:]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "idx = randint(0, img_paths.__len__()-1)\n",
    "# idx = 60\n",
    "print(idx)\n",
    "og_img = utils.rotate_to_vertical(img_paths[idx])\n",
    "# red = og_img[...,0]\n",
    "# red = cv2.GaussianBlur(red, (11, 11), 5)\n",
    "# red = (red > 4).astype(np.uint8)\n",
    "\n",
    "def gamma_correction(image, gamma):\n",
    "  image = image / 255.0\n",
    "  corrected = np.power(image, gamma)\n",
    "  return np.uint8(corrected * 255.0)\n",
    "\n",
    "\n",
    "red_green = og_img[...,:2].mean(axis=-1)\n",
    "red_green = cv2.GaussianBlur(red_green, (11, 11), 5)\n",
    "# plt.imshow(red_green)\n",
    "\n",
    "gamma_rg = gamma_correction(red_green, gamma=2.5)\n",
    "gamma_rg = gamma_rg > 20\n",
    "_, labels, bboxes, _ = cv2.connectedComponentsWithStats(gamma_rg.astype(np.uint8), connectivity=8)\n",
    "\n",
    "# plt.imshow(og_img, cmap='gray', alpha=0.5)\n",
    "for box in bboxes[1:]:\n",
    "    x,y,w,h,area = box\n",
    "    if area > 5000:\n",
    "        # plt.gca().add_patch(patches.Rectangle((x-5,y),w+10,h,facecolor='none',edgecolor='white'))\n",
    "        lx1 = x + w\n",
    "        lx2 = x + h + w\n",
    "        og_w, og_h = og_img.shape[:2]\n",
    "        ly = y + h\n",
    "        # plt.gca().add_patch(patches.Rectangle((lx1,ly),lx2-lx1,og_h-ly,facecolor='none',edgecolor='red'))\n",
    "        # og_img[ly:og_img.shape[0],x-15:x+w+15,:] = 0\n",
    "        og_img[ly:og_img.shape[0],x-15:x+w+15,:] = 0\n",
    "        # plt.gca().add_patch(patches.Rectangle((x-5,ly),w+10,og_h,facecolor='none',edgecolor='red'))\n",
    "plt.imshow(og_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = img_paths.__len__()  # total number of images\n",
    "grid_shape = (int(np.sqrt(n))+1, int(np.sqrt(n))+1)\n",
    "fig, axs = plt.subplots(nrows=grid_shape[0], ncols=grid_shape[1], figsize=(25, 25))\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, img_p in tqdm_notebook(enumerate(img_paths)):\n",
    "    og_img = utils.rotate_to_vertical(img_p)\n",
    "    \n",
    "    # c_img, og_img, cvt_img, enhanced_img, img_dilate = get_enhanced_image(image_path=img_p, apply_dilation=True, apply_blur=True, apply_ce=True)\n",
    "    # t_img = get_threshold_img(img_dilate, apply_open=True, apply_erode_n_dilate=True)\n",
    "    # bboxes = get_contours_n_bbox(t_img)\n",
    "    \n",
    "    ax = axs[i]\n",
    "    red = og_img[...,0]\n",
    "    red = cv2.GaussianBlur(red, (11, 11), 5)\n",
    "# blurred = cv2.GaussianBlur(enhanced_img, (11, 11), 5)\n",
    "    # axs[1].imshow(blurred)\n",
    "    red = (red > 4).astype(np.uint8)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 3))  # Adjust kernel size as needed\n",
    "    eroded = cv2.erode(red, kernel, iterations=5)\n",
    "    \n",
    "    ax.imshow(red)\n",
    "    # cv2.connectedComponentsWithStats(red, connectivity=4)   \n",
    "    # ax.imshow(eroded, cmap='gray', alpha=0.5)\n",
    "    # ax.imshow(t_img, alpha=0.5)\n",
    "    # for bbox in bboxes:\n",
    "    #     ax.add_patch(patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], facecolor='none', edgecolor='white'))\n",
    "    \n",
    "    ax.set_title(i)\n",
    "    ax.axis('off')\n",
    "\n",
    "for ax in axs[n:]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_image_2(img, apply_ce=False, apply_blur=False, apply_clahe=False, apply_dilation=False):\n",
    "    # c_img = utils.rotate_to_vertical(image_path)\n",
    "    og_img = img\n",
    "    c_img = cv2.cvtColor(og_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if apply_clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(32,32))\n",
    "        c_img = clahe.apply(c_img)\n",
    "    \n",
    "    if apply_ce:\n",
    "        c_img = cv2.equalizeHist(c_img)\n",
    "    \n",
    "    if apply_blur:\n",
    "        c_img = cv2.GaussianBlur(c_img, (51, 51), 15)\n",
    "\n",
    "\n",
    "    cvt_img = cv2.cvtColor(og_img, cv2.COLOR_RGB2LAB)\n",
    "    # cvt_img = og_img\n",
    "    # img_dilate = None\n",
    "    \n",
    "    enhanced_img = cv2.convertScaleAbs(cvt_img[...,0], alpha=2,beta=-70)\n",
    "    if apply_dilation:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # Adjust kernel size as needed\n",
    "        img_dilate = cv2.dilate(enhanced_img, kernel, iterations=2)\n",
    "    \n",
    "    return c_img, og_img, cvt_img, enhanced_img, img_dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_img = cv2.equalizeHist(og_img[...,-1])\n",
    "fig, axs = plt.subplots(1,5, figsize=(16,5))\n",
    "for i in range(4):\n",
    "    axs[i].axis('off')\n",
    "\n",
    "c_img, og_img, cvt_img, enhanced_img, img_dilate = get_enhanced_image_2(og_img, apply_dilation=True)\n",
    "\n",
    "\n",
    "e_img = cv2.convertScaleAbs(og_img[...,[1,2]].mean(axis=-1), alpha=2,beta=-90)\n",
    "axs[0].imshow(enhanced_img)\n",
    "\n",
    "# blurred = cv2.GaussianBlur(og_img.mean(axis=-1).astype(np.uint8), (11, 11), 5)\n",
    "# blurred = cv2.GaussianBlur(og_img[...,[0,2]].mean(axis=-1).astype(np.uint8), (11, 11), 5)\n",
    "blurred = cv2.GaussianBlur(enhanced_img, (11, 11), 5)\n",
    "# blurred = cv2.GaussianBlur(enhanced_img, (11, 11), 5)\n",
    "axs[1].imshow(blurred)\n",
    "# thresh = cv2.adaptiveThreshold(enhanced_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,31, 5)\n",
    "thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51, 5)\n",
    "axs[2].imshow(thresh)\n",
    "\n",
    "# kernel = np.ones((7, 7), np.uint8)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))  # Adjust kernel size as needed\n",
    "eroded = cv2.erode(thresh, kernel, iterations=2)\n",
    "axs[3].imshow(eroded)\n",
    "\n",
    "# opening = cv2.morphologyEx(thresh[thresh.shape[0] // 2:,...], cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "# new_thresh = thresh\n",
    "# new_thresh[thresh.shape[0] // 2:,...] = opening\n",
    "# axs[3].imshow(new_thresh)\n",
    "# edges = cv2.Canny(eroded, 200, 255, L2gradient=True)\n",
    "# axs[4].imshow(edges)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_pipeline(img_p, apply_erode=False):\n",
    "    def gamma_correction(image, gamma):\n",
    "        image = image / 255.0\n",
    "        corrected = np.power(image, gamma)\n",
    "        return np.uint8(corrected * 255.0)\n",
    "    \n",
    "    c_img, og_img, cvt_img, enhanced_img, img_dilate = get_enhanced_image(img_p, apply_dilation=True)\n",
    "    red_green = og_img[...,:2].mean(axis=-1)\n",
    "    red_green = cv2.GaussianBlur(red_green, (11, 11), 5)\n",
    "    gamma_rg = gamma_correction(red_green, gamma=2.0)\n",
    "    gamma_rg_int = (gamma_rg > 20).astype(np.uint8) * 255\n",
    "    \n",
    "    # blurred = cv2.GaussianBlur(enhanced_img, (11, 11), 5)\n",
    "    # blurred = cv2.GaussianBlur(gamma_rg, (11, 11), 5)\n",
    "    thresh = cv2.adaptiveThreshold(gamma_rg, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,21, 5)\n",
    "    \n",
    "    if apply_erode:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))  # Adjust kernel size as needed\n",
    "        thresh = cv2.erode(thresh, kernel, iterations=2)\n",
    "\n",
    "    _, labels, bboxes, _ = cv2.connectedComponentsWithStats(gamma_rg_int, connectivity=8)\n",
    "\n",
    "    \n",
    "    for box in bboxes[1:]:\n",
    "        x,y,w,h,area = box\n",
    "        if area > 5000:\n",
    "            thresh[y + h:og_img.shape[0],x-30:x+w+30] = 0\n",
    "\n",
    "    return (bboxes, thresh, og_img)\n",
    "    \n",
    "    # plt.imshow(og_img)\n",
    "    # plt.imshow(thresh, cmap='gray',alpha=0.5)\n",
    "    \n",
    "    # for box in bboxes[1:]:\n",
    "    #     x,y,w,h,area = box\n",
    "    #     if area > 5000:\n",
    "    #         plt.gca().add_patch(patches.Rectangle((x,y),w,h,edgecolor='red', facecolor='none'))\n",
    "\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = randint(0, img_paths.__len__()-1)\n",
    "# print(idx)\n",
    "# mixed_pipeline(img_p=img_paths[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_extracted_imgs = []\n",
    "\n",
    "n = img_paths.__len__()\n",
    "grid_shape = (int(np.sqrt(n))+1, int(np.sqrt(n))+1)\n",
    "\n",
    "for i, img_p in tqdm_notebook(enumerate(img_paths)):\n",
    "    bboxes, thresh, og_img = mixed_pipeline(img_p=img_p)\n",
    "    roi_extracted_img = np.zeros_like(og_img)\n",
    "    for box in bboxes[1:]:\n",
    "        x,y,w,h,area = box\n",
    "        if area > 10000:\n",
    "            # ax.add_patch(patches.Rectangle((x-10,0),w+20,h+y,edgecolor='red', facecolor='none'))\n",
    "            roi_extracted_img[0:h+y, x-15:x+w+30] = og_img[0:h+y, x-15:x+w+30]\n",
    "    \n",
    "    roi_extracted_imgs.append(roi_extracted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_img = cv2.cvtColor(roi_extracted_imgs[0], cv2.COLOR_RGB2LAB)\n",
    "gamma_cvt_img = gamma_correction(cv2.convertScaleAbs(cvt_img[...,0], alpha=2.0,beta=100), gamma=2.5)\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(gamma_cvt_img,cmap='gray')\n",
    "axs[1].imshow(cvt_img[...,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.clip(roi_extracted_imgs[0][...,0] * roi_extracted_imgs[0][...,1],a_max=255, a_min=0))\n",
    "idx = 21\n",
    "i = gamma_correction(cv2.convertScaleAbs(roi_extracted_imgs[idx][...,0] * roi_extracted_imgs[idx][...,1], alpha=2.0,beta=100), gamma=2.0)\n",
    "min_max_scale = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(roi_extracted_imgs[idx])\n",
    "axs[1].imshow(min_max_scale(cv2.GaussianBlur(i,(11,11), sigmaX=9, sigmaY=9))>0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow()\n",
    "\n",
    "test_img = roi_extracted_imgs[0]\n",
    "test_img = min_max_scale(test_img)\n",
    "plt.imshow(test_img[...,0] + test_img[...,1])\n",
    "plt.show()\n",
    "plt.imshow(test_img[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = glob.glob('../../../dataset/Seek Thermal/masks/*.png')\n",
    "new_img_paths = ['D:/semester 1 study/Goettingen study material/Practical Course Data Fusion/dataset/Seek Thermal/jpegs/'+x.split('\\\\')[-1].replace('png','jpg') for x in mask_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = imageio.imread(mask_paths[0])\n",
    "mask = mask == 2\n",
    "\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "_, axs = plt.subplots(1,3)\n",
    "for i in range(3):\n",
    "    # axs[i].imshow(og_img[...,i])\n",
    "    axs[i].imshow(roi_extracted_imgs[idx][...,i])\n",
    "    axs[i].axis('off')\n",
    "plt.title('ORIGINAL')\n",
    "    \n",
    "for color, color_conv in color_convs.items():\n",
    "    # cvt_img = cv2.cvtColor(og_img, color_conv)\n",
    "    cvt_img = cv2.cvtColor(roi_extracted_imgs[idx], color_conv)\n",
    "    _, axs = plt.subplots(1,3)\n",
    "    for i in range(3):\n",
    "        axs[i].imshow(cvt_img[...,i], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.title(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 20\n",
    "\n",
    "yuv_img = cv2.cvtColor(roi_extracted_imgs[idx], cv2.COLOR_RGB2YUV)\n",
    "\n",
    "fig, axs = plt.subplots(1,3)\n",
    "axs[0].imshow(roi_extracted_imgs[idx][...,0])\n",
    "axs[1].imshow(yuv_img[...,-1], cmap='gray', alpha=0.5)\n",
    "axs[2].imshow(yuv_img[...,-1], cmap='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi_extracted_imgs[idx][...,0] * yuv_img[...,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "idx = randint(0, img_paths.__len__()-1)\n",
    "og_img = utils.rotate_to_vertical(img_paths[idx])\n",
    "print(idx)\n",
    "cvt_img = cv2.cvtColor(og_img,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "gam_cvt_img = gamma_correction(cv2.convertScaleAbs(cvt_img[...,-1], alpha=1.0,beta=-20), gamma=2.0)\n",
    "\n",
    "adap_thresh = cv2.adaptiveThreshold(gam_cvt_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 7)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))  # Adjust kernel size as needed\n",
    "img_dilate = cv2.dilate(adap_thresh, kernel, iterations=3)\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(gam_cvt_img,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(img_dilate,cmap='gray')\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adap_thresh = cv2.adaptiveThreshold(gam_cvt_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 31, 7)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # Adjust kernel size as needed\n",
    "img_dilate = cv2.dilate(adap_thresh, kernel, iterations=3)\n",
    "# cv2.dilate(adap_thresh, )\n",
    "plt.imshow(img_dilate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_img = get_threshold_img(gam_cvt_img, apply_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = get_contours_n_bbox(t_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(og_img)\n",
    "for bbox in bboxes:\n",
    "    plt.gca().add_patch(patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], facecolor='none', edgecolor='red'))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1,3)\n",
    "for i in range(3):\n",
    "    # axs[i].imshow(og_img[...,i])\n",
    "    axs[i].imshow(og_img[...,i])\n",
    "    axs[i].axis('off')\n",
    "plt.title('ORIGINAL')\n",
    "    \n",
    "for color, color_conv in color_convs.items():\n",
    "    # cvt_img = cv2.cvtColor(og_img, color_conv)\n",
    "    converted_img = cv2.cvtColor(og_img, color_conv)\n",
    "    _, axs = plt.subplots(1,3)\n",
    "    for i in range(3):\n",
    "        axs[i].imshow(converted_img[...,i])\n",
    "        axs[i].axis('off')\n",
    "    plt.title(color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermal_cam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
