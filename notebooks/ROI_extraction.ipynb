{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for ROI Extraction\n",
    "We will start with adjusting the color space\n",
    "From some EDA, I have found LAB, LUV and YUV colors spaces to be useful for ROI extraction task\n",
    "\n",
    "Here's the current pipeline\n",
    "- Convert RGB image into another color space (possibly LAB)\n",
    "- Extract L channel and apply enhancement using `convertScaleAbs` function from cv2 [alpha = 2.0, beta=-50]\n",
    "- Dilate image to increase ROI area\n",
    "- Apply binary threshold on the image with threshold value of 200\n",
    "- Applying `findContours` on the thresholded image\n",
    "- Fetch each contours area and sort in descending order.\n",
    "- Pick highest contour area objects and create bounding boxes using `boundingRect`\n",
    "- These will be used as ROIs for extraction of hot liquid\n",
    "\n",
    "- Need to apply some kind of technique to identify how many objects are there in the frame. \n",
    "    - Also, how do we know the ROI is actually a coffee mug or glass or something else.\n",
    "        Template Matching, or maybe some other technique. \n",
    "            Some kind of edge detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio as io\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "from matplotlib import patches\n",
    "from pycocotools import mask as M\n",
    "from pprint import pprint\n",
    "sys.path.append('../scripts')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.yaml','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "img_paths = sorted(glob.glob(config['dataset']['images']+'/img_thermal_*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('D:/semester 1 study/Goettingen study material/Practical Course Data '\n",
      " 'Fusion/dataset/images\\\\img_thermal_1709304217421.jpg')\n"
     ]
    }
   ],
   "source": [
    "pprint(img_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_convs = {\n",
    "    'HLS':cv2.COLOR_RGB2HLS,\n",
    "    'HSV': cv2.COLOR_RGB2HSV,\n",
    "    'LAB':cv2.COLOR_RGB2LAB,\n",
    "    'LUV': cv2.COLOR_RGB2LUV,\n",
    "    'YUV': cv2.COLOR_RGB2YUV\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_image(image_path, apply_ce=False, apply_blur=False, apply_clahe=False, apply_dilation=False):\n",
    "    _, c_img = utils.extract_image_and_spectrum(utils.rotate_to_vertical(image_path))\n",
    "    og_img = c_img\n",
    "    c_img = cv2.cvtColor(c_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if apply_clahe:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(32,32))\n",
    "        c_img = clahe.apply(c_img)\n",
    "    \n",
    "    if apply_ce:\n",
    "        c_img = cv2.equalizeHist(c_img)\n",
    "    \n",
    "    if apply_blur:\n",
    "        c_img = cv2.GaussianBlur(c_img, (51, 51), 15)\n",
    "\n",
    "    cvt_img = cv2.cvtColor(og_img, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    img_dilate = None\n",
    "    \n",
    "    enhanced_img = cv2.convertScaleAbs(cvt_img[...,-1], alpha=2,beta=-40)\n",
    "    if apply_dilation:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # Adjust kernel size as needed\n",
    "        img_dilate = cv2.dilate(enhanced_img, kernel, iterations=2)\n",
    "    \n",
    "    return c_img, og_img, cvt_img, enhanced_img, img_dilate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_img, og_img, cvt_img, enhanced_img, img_dilate = get_enhanced_image(image_path=img_paths[0], apply_dilation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_img(img, t_value=200, apply_open=False, apply_erode_n_dilate=False):\n",
    "    _, img = cv2.threshold(img_dilate, t_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    if apply_open:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31, 31))  # Adjust kernel size as needed\n",
    "        opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "        img = opened\n",
    "        \n",
    "    if apply_erode_n_dilate:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6, 6))  # Adjust kernel size as needed\n",
    "        eroded = cv2.erode(img, kernel, iterations=6)\n",
    "        dilated = cv2.dilate(eroded, kernel, iterations=4)\n",
    "        img = dilated\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_n_bbox(img):\n",
    "    contours, _ = cv2.findContours(img.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_contours = [np.squeeze(c, axis=1) for c in contours]\n",
    "\n",
    "    contour_areas = pd.DataFrame([(int(i), cv2.contourArea(c)) for i, c in enumerate(contours)])\n",
    "    contour_areas.columns = ['index', 'area']\n",
    "    contour_areas.sort_values('area', ascending=False, inplace=True)\n",
    "    contour_areas['index'] = contour_areas['index'].astype(int)\n",
    "    \n",
    "    bboxes = [cv2.boundingRect(new_contours[int(row[0])]) for idx, row in enumerate(contour_areas.iloc[:3].values)]\n",
    "    \n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATTERN MATCHING MISSING!\n",
    "important for identifying if the identified ROI is of a glass/mug or something else hot\n",
    "    - might have to make use of other channels to see if liquid is in the mug and is possibly less than the height of the cup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermal_cam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
