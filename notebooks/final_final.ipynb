{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lightning import LightningModule, LightningDataModule\n",
    "# import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tf\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pycocotools\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm.notebook import tqdm\n",
    "import imageio\n",
    "import os\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "import utils\n",
    "import lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob(f'{MAIN_PATH}/Seek Thermal/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = '../../../dataset/Seek Thermal'\n",
    "ANNOT_PATH = f'{MAIN_PATH}/rough_annots.json'\n",
    "# IMAGES_PATHS = sorted(glob(MAIN_PATH+'/Seek Thermal/jpegs/*'))\n",
    "MASKS_PATHS = sorted(glob(MAIN_PATH+'/masks/*.png'))\n",
    "IMAGES_PATHS = [f'{MAIN_PATH}/jpegs/'+x.split('\\\\')[-1].replace('png','jpg') for x in MASKS_PATHS]\n",
    "\n",
    "with open(ANNOT_PATH, 'r') as f:\n",
    "    annot = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoteSensingDataset(Dataset):\n",
    "    def __init__(self, rasters, targets, width=512, transform=None):\n",
    "        self.rasters = rasters\n",
    "        self.targets = targets\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rasters)\n",
    "\n",
    "    def read_image(self, path):\n",
    "        return imageio.imread(path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raster = utils.rotate_to_vertical(self.rasters[idx])\n",
    "        img_w, img_h = raster.shape[:2]\n",
    "        target = self.read_image(self.targets[idx])[:img_w,:img_h]\n",
    "\n",
    "        if self.width:\n",
    "            raster = cv2.resize(raster,(self.width, self.width), interpolation=cv2.INTER_CUBIC)\n",
    "            target = cv2.resize(target,(self.width, self.width), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        temp_target = np.stack([target, target], axis=-1)\n",
    "        temp_target[...,0] = temp_target[...,0] > 0\n",
    "        temp_target[...,1] = temp_target[...,1] == 2\n",
    "        temp_target = temp_target.astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=raster, mask=temp_target)\n",
    "            raster = transformed[\"image\"]\n",
    "            target = transformed[\"mask\"]\n",
    "\n",
    "        return raster.float(), target.float().permute(0,1,2)\n",
    "\n",
    "class ThermalDataModule(LightningDataModule):\n",
    "    def __init__(self, rasters, targets, training_split=0.7, batch_size=16, width=512,\n",
    "                 train_augmentation=None, val_augmentation=None, normalize=False,\n",
    "                 shuffle=True, deterministic=True, train_indices=None, val_indices=None):\n",
    "        super().__init__()\n",
    "        self.rasters = rasters\n",
    "        self.targets = targets\n",
    "        self.training_split = training_split\n",
    "        self.batch_size = batch_size\n",
    "        self.train_augmentation = train_augmentation\n",
    "        self.val_augmentation = val_augmentation\n",
    "        self.normalize = normalize\n",
    "        self.width = width\n",
    "        self.shuffle = shuffle\n",
    "        self.deterministic = deterministic\n",
    "        self.train_indices = train_indices\n",
    "        self.val_indices = val_indices\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Split dataset into train and validation sets\n",
    "        num_samples = len(self.rasters)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.train_indices is None and self.val_indices is None:\n",
    "            split_idx = int(self.training_split * num_samples)\n",
    "            self.train_indices = indices[:split_idx]\n",
    "            self.val_indices = indices[split_idx:]\n",
    "\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = RemoteSensingDataset([self.rasters[i] for i in self.train_indices],\n",
    "                                             [self.targets[i] for i in self.train_indices],\n",
    "                                             width=self.width,\n",
    "                                             transform=self.train_augmentation)\n",
    "        val_dataset = RemoteSensingDataset([self.rasters[i] for i in self.val_indices],\n",
    "                                           [self.targets[i] for i in self.val_indices],\n",
    "                                             width=self.width,\n",
    "                                           transform=self.val_augmentation)\n",
    "\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = len(MASKS_PATHS)\n",
    "indices = np.arange(NUM_SAMPLES)\n",
    "TRAINING_SPLIT = 0.7\n",
    "split_idx = int(TRAINING_SPLIT * NUM_SAMPLES)\n",
    "train_indices = indices[:split_idx]\n",
    "val_indices = indices[split_idx:]\n",
    "\n",
    "training_image_paths = [IMAGES_PATHS[i] for i in train_indices]\n",
    "training_masks_paths = [MASKS_PATHS[i] for i in train_indices]\n",
    "\n",
    "val_image_paths = [IMAGES_PATHS[i] for i in val_indices]\n",
    "val_masks_paths = [MASKS_PATHS[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_img_proc_ds = ThermalDataModule(rasters=IMAGES_PATHS, targets=MASKS_PATHS)\n",
    "# ml_proc_ds = ThermalDataModule(rasters=IMAGES_PATHS, targets=MASKS_PATHS)\n",
    "\n",
    "simple_img_proc_ds = RemoteSensingDataset(training_image_paths, training_masks_paths, width=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb107078b85d40e185c1e2c5072284ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7f19d37f0b4e868a3b9f89203bd817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayan.Gupta\\AppData\\Local\\Temp\\ipykernel_13860\\3787196538.py:20: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  train_masks = [imageio.imread(x) for x in mask_paths]\n"
     ]
    }
   ],
   "source": [
    "def ROI_extraction(img_paths):\n",
    "    roi_imgs = []\n",
    "    for i, img_p in tqdm_notebook(enumerate(img_paths)):\n",
    "        bboxes, thresh, og_img = utils.mixed_pipeline(img_p=img_p)\n",
    "        # roi_extracted_img = np.zeros_like(og_img)\n",
    "        for box in bboxes[1:]:\n",
    "            roi_extracted_img = np.zeros_like(og_img)\n",
    "            x,y,w,h,area = box\n",
    "            if area > 7500:\n",
    "                # ax.add_patch(patches.Rectangle((x-10,0),w+20,h+y,edgecolor='red', facecolor='none'))\n",
    "                roi_extracted_img[0:h+y, x-15:x+w+30] = og_img[0:h+y, x-15:x+w+30]\n",
    "\n",
    "            roi_imgs.append([box, roi_extracted_img])\n",
    "    return roi_imgs\n",
    "\n",
    "train_roi_imgs = ROI_extraction(training_image_paths)\n",
    "val_roi_imgs = ROI_extraction(val_image_paths)\n",
    "\n",
    "def mask_reading(mask_paths):\n",
    "    train_masks = [imageio.imread(x) for x in mask_paths]\n",
    "    cups_masks = [(mask == 1).astype(np.uint8) for mask in train_masks]\n",
    "    # cv2.connectedComponents()\n",
    "    comps, labels = cv2.connectedComponents(train_masks[-5])\n",
    "    ohe_mask = np.eye(comps)[labels]\n",
    "    # code goes here\n",
    "    ...\n",
    "    # train_masks = [(mask == 2).astype(np.uint8) for mask in train_masks]\n",
    "    return new_train_masks\n",
    "\n",
    "train_masks = mask_reading(training_masks_paths)\n",
    "val_masks = mask_reading(val_masks_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1280, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comps, labels = cv2.connectedComponents(train_masks[-5])\n",
    "ohe_mask = np.eye(comps)[labels]\n",
    "\n",
    "\n",
    "# print(comps)\n",
    "\n",
    "# fig, axs = plt.subplots(1, comps-1)\n",
    "# for i in range(0,comps-1):\n",
    "#     if comps - 1 == 1:\n",
    "#         axs.axis('off')\n",
    "#         axs.imshow(ohe_mask[...,i+1])\n",
    "#     else:\n",
    "#         axs[i].axis('off')\n",
    "#         axs[i].imshow(ohe_mask[...,i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_roi_imgs.__len__()\n",
    "\n",
    "# sample_img = roi_extracted_imgs[i][1].copy()\n",
    "# bbox = roi_extracted_imgs[i][0][0]\n",
    "# filtered_green = sample_img[...,1] * sample_img[...,0] > 20\n",
    "# e_img = np.stack([sample_img[...,0],filtered_green, sample_img[...,-1]], -1)\n",
    "# gray_img = gamma_correction(cv2.cvtColor(e_img, cv2.COLOR_RGB2GRAY), gamma=2.0)\n",
    "# scaled_gray_img = min_max_scale(gray_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermal_cam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
